lisp解释器：
首先前端进行词法，语义，语法分析生成ast树
后端进行中间代码生成（自己的汇编语法）-》汇编 ->目标语言。
自己定义了一门lisp语言，实现了逻辑运算，判断语句，大小比较，变量，输出打印。
词法分析： 首先将自己定义的语言拆分成一个一个字符，然后对每个字符解析，删除不必要的字符。
只需要逻辑操作符，各种括号，变量，字符串，数值，分号等字符
语法分析（ast树）
对字符串进行解析，解析出一条一条的语句。然后对每个语句进行解析。
后端：
因为自己不是很懂汇编语言，所以我对前端的ast树解析以后，只是将其转化成Python语言
然后再用Python语言进行编写的。
不过我实现了中间代码生成这一部分，我定义了一门自己的汇编逻辑。然后转成相应的机器代码。


爬虫可视化：
syncrequest获取要爬取网站的页面数据
然后呢将爬取页面保存到本地，
这样下次爬虫解析数据就可以更快的获取。
首先运用node.js的cheerio解析页面。
如何可视化呢？
用node express搭建一个服务器，注册路由函数,启动服务器
index页面开发独立的ajax应用，获取到所有的movies信息
然后将movies信息通过lodash进行分类，结合echart生成可视化数据渲染到页面。

todo清单：
用node express搭建一个服务器，注册路由函数,启动服务器
前端使用 React框架实现Todo清单,
实现了todo计数组件，Todo状态组件
通过 BrowserRouter 和 Router 渲染单页路由
然后实现组件通信更新数据
特点利用cors解决了跨域冲突，如何实现单个todoitem是的与计数器组件也同步更新。
这里利用了子组件和父组件通信原理，todo将自己的更新和删除函数传给todolist, todolist将自己
的更新和删除传给todoitem,todoitem通过props属性获取到todo的更新和删除函数，这样todoitem
更新和删除的时候，todolist能够将变化的信息传递个todoCounter组件。就实现了信息同步。

flask+web开发：
如何实现分页：
通过url和falsk request解析出当前页面下标
然后通过全局定义的一页多少个博客，flask_sqlalchemy的 paginate获取相应的博客。

如何实现获取当前用户的所有跟随的人的博客：
数据库查询所有用户的追随者的id找到与自己id相同的用户。
然后查找所有post的用户id和这些用户的id相同的帖子。
然后union内联自己的所有帖子，然后通过时间排序。
